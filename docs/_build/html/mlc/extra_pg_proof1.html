

<!DOCTYPE html>
<html class="writer-html4" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Extra Material &mdash; Machine Learning Control 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/modify.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../user/installation.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Control</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../control/control.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../control/running.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../control/saving_and_loading.html">Experiment Outputs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../control/plotting.html">Plotting Results</a></li>
</ul>
<p class="caption"><span class="caption-text">Hardware</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../hardware/hardware.html">Hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware/supported.html">Supported hardware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware/deploy.html">Deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Utilities Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../utils/logger.html">Logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/plotter.html">Plotter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/mpi.html">MPI Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/run_utils.html">Run Utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Zone</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/release_dev.html">Release package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/doc_dev.html">Release documentation</a></li>
</ul>
<p class="caption"><span class="caption-text">Etc.</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../etc/acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../etc/author.html">About the Author</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Machine Learning Control</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Extra Material</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/mlc/extra_pg_proof1.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="extra-material">
<h1>Extra Material<a class="headerlink" href="#extra-material" title="Permalink to this headline">¶</a></h1>
<div class="section" id="proof-for-don-t-let-the-past-distract-you">
<h2>Proof for Don’t Let the Past Distract You<a class="headerlink" href="#proof-for-don-t-let-the-past-distract-you" title="Permalink to this headline">¶</a></h2>
<p>In this subsection, we will prove that actions should not be reinforced for rewards obtained in the past.</p>
<p>Expand out <img class="math" src="../_images/math/c2d6738c058406ade40dcf870311db157ed80e0f.svg" alt="R(\tau)"/> in the expression for the <a class="reference external" href="../spinningup/rl_intro3.html#deriving-the-simplest-policy-gradient">simplest policy gradient</a> to obtain:</p>
<div class="math">
<p><img src="../_images/math/78dcf57bb6ffe8322e17954ab757a82b4ce91400.svg" alt="\nabla_{\theta} J(\pi_{\theta}) &amp;= \underE{\tau \sim \pi_{\theta}}{\sum_{t=0}^{T} \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(\tau)} \\
&amp;= \underE{\tau \sim \pi_{\theta}}{\sum_{t=0}^{T} \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \sum_{t'=0}^T R(s_{t'}, a_{t'}, s_{t'+1})} \\
&amp;= \sum_{t=0}^{T} \sum_{t'=0}^T  \underE{\tau \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(s_{t'}, a_{t'}, s_{t'+1})},"/></p>
</div><p>and consider the term</p>
<div class="math">
<p><img src="../_images/math/43a546d997bc6ea6dcd803c77182c1c64473812a.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')} = \underE{\tau \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(s_{t'}, a_{t'}, s_{t'+1})}."/></p>
</div><p>We will show that for the case of <img class="math" src="../_images/math/e5c189df93dba493361739f87479653a56ade5de.svg" alt="t' &lt; t"/> (the reward comes before the action being reinforced), this term is zero. This is a complete proof of the original claim, because after dropping terms with <img class="math" src="../_images/math/e5c189df93dba493361739f87479653a56ade5de.svg" alt="t' &lt; t"/> from the expression, we are left with the reward-to-go form of the policy gradient, as desired:</p>
<div class="math">
<p><img src="../_images/math/1f46bd358493eaf0082ceb6049d6faaaa5a32792.svg" alt="\nabla_{\theta} J(\pi_{\theta}) = \underE{\tau \sim \pi_{\theta}}{\sum_{t=0}^{T} \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \sum_{t'=t}^T R(s_{t'}, a_{t'}, s_{t'+1})}"/></p>
</div><p><strong>1. Using the Marginal Distribution.</strong> To proceed, we have to break down the expectation in <img class="math" src="../_images/math/3ab189097d757b1aee8243d7e0de33823e55fba0.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')}"/>. It’s an expectation over trajectories, but the expression inside the expectation only deals with a few states and actions: <img class="math" src="../_images/math/4fcf0bf03c2a691496ce04ade269159d8b89caa5.svg" alt="s_t"/>, <img class="math" src="../_images/math/39079fcebc9eb2aba4ab3fe7359b34807ceccc0e.svg" alt="a_t"/>, <img class="math" src="../_images/math/80c57cd33b89fa82edfee3891ed216da03604619.svg" alt="s_{t'}"/>, <img class="math" src="../_images/math/10c7715c2f74a6214dc6ccced795282000166814.svg" alt="a_{t'}"/>, and <img class="math" src="../_images/math/a48bd0ba1c9bb7b3a764b0e04201811cf4e349c6.svg" alt="s_{t'+1}"/>. So in computing the expectation, we only need to worry about the <a class="reference external" href="https://en.wikipedia.org/wiki/Marginal_distribution">marginal distribution</a> over these random variables.</p>
<p>We derive:</p>
<div class="math">
<p><img src="../_images/math/329e4574e471e12c8d36bc66dd41ce755ca4817a.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')} &amp;= \int_{\tau} P(\tau|\pi_{\theta}) f(t,t') \\
&amp;= \int_{s_t, a_t, s_{t'}, a_{t'}, s_{t'+1}} P(s_t, a_t, s_{t'}, a_{t'}, s_{t'+1} | \pi_{\theta}) f(t,t') \\
&amp;= \underE{s_t, a_t, s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{f(t,t')}."/></p>
</div><p><strong>2. Probability Chain Rule.</strong> Joint distributions can be calculated in terms of conditional and marginal probabilities via <a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>: <img class="math" src="../_images/math/8992ade0c88bbe292243c9a330e3a5d01f29da37.svg" alt="P(A,B) = P(B|A) P(A)"/>. Here, we use this rule to compute</p>
<div class="math">
<p><img src="../_images/math/cca213cea4ba9ca025b3d6fbdc9a6eb769876c0c.svg" alt="P(s_t, a_t, s_{t'}, a_{t'}, s_{t'+1} | \pi_{\theta}) = P(s_t, a_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}) P(s_{t'}, a_{t'}, s_{t'+1} | \pi_{\theta})"/></p>
</div><p><strong>3. Separating Expectations Over Multiple Random Variables.</strong> If we have an expectation over two random variables <img class="math" src="../_images/math/a236fe76423c33d18465350c1c36cef9aa8fdc31.svg" alt="A"/> and <img class="math" src="../_images/math/3661a93c505458c8238dd42d089cd68cc4b18727.svg" alt="B"/>, we can split it into an inner and outer expectation, where the inner expectation treats the variable from the outer expectation as a constant. Our ability to make this split relies on probability chain rule. Mathematically:</p>
<div class="math">
<p><img src="../_images/math/6e479c31e0f4d437e88cc84caead8646ff85774a.svg" alt="\underE{A,B}{f(A,B)} &amp;= \int_{A,B} P(A,B) f(A,B) \\
&amp;= \int_{A} \int_B P(B|A) P(A) f(A,B) \\
&amp;= \int_A P(A) \int_B P(B|A) f(A,B) \\
&amp;= \int_A P(A) \underE{B}{f(A,B) \Big| A} \\
&amp;= \underE{A}{\underE{B}{f(A,B) \Big| A} }"/></p>
</div><p>An expectation over <img class="math" src="../_images/math/51efb0c44f6ee7e0a8033c1768f4db7cb3d8cba3.svg" alt="s_t, a_t, s_{t'}, a_{t'}, s_{t'+1}"/> can thus be expressed by</p>
<div class="math">
<p><img src="../_images/math/43ab88ab34355d7997247705216f100724d9211f.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')} &amp;= \underE{s_t, a_t, s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{f(t,t')} \\
&amp;= \underE{s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{\underE{s_t, a_t \sim \pi_{\theta}}{f(t,t') \Big| s_{t'}, a_{t'}, s_{t'+1}}}"/></p>
</div><p><strong>4. Constants Can Be Pulled Outside of Expectations.</strong> If a term inside an expectation is constant with respect to the variable being expected over, it can be pulled outside of the expectation. To give an example, consider again an expectation over two random variables <img class="math" src="../_images/math/a236fe76423c33d18465350c1c36cef9aa8fdc31.svg" alt="A"/> and <img class="math" src="../_images/math/3661a93c505458c8238dd42d089cd68cc4b18727.svg" alt="B"/>, where this time, <img class="math" src="../_images/math/07f71bb2dff1e2b911ec6f9e4ffa7ba8ffb7f1be.svg" alt="f(A,B) = h(A) g(B)"/>. Then, using the result from before:</p>
<div class="math">
<p><img src="../_images/math/b237118c6609247fe9a6c3bdb893292e936e53e6.svg" alt="\underE{A,B}{f(A,B)} &amp;= \underE{A}{\underE{B}{f(A,B) \Big| A}} \\
&amp;= \underE{A}{\underE{B}{h(A) g(B) \Big| A}}\\
&amp;= \underE{A}{h(A) \underE{B}{g(B) \Big| A}}."/></p>
</div><p>The function in our expectation decomposes this way, allowing us to write:</p>
<div class="math">
<p><img src="../_images/math/9245c7f4146e8bc7a7742bdb337c68658e4c69d8.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')} &amp;= \underE{s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{\underE{s_t, a_t \sim \pi_{\theta}}{f(t,t') \Big| s_{t'}, a_{t'}, s_{t'+1}}} \\
&amp;= \underE{s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{\underE{s_t, a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) R(s_{t'}, a_{t'}, s_{t'+1}) \Big| s_{t'}, a_{t'}, s_{t'+1}}} \\
&amp;= \underE{s_{t'}, a_{t'}, s_{t'+1} \sim \pi_{\theta}}{R(s_{t'}, a_{t'}, s_{t'+1})  \underE{s_t, a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \Big| s_{t'}, a_{t'}, s_{t'+1}}}."/></p>
</div><p><strong>5. Applying the EGLP Lemma.</strong> The last step in our proof relies on the <a class="reference external" href="../spinningup/rl_intro3.html#expected-grad-log-prob-lemma">EGLP lemma</a>. At this point, we will only worry about the innermost expectation,</p>
<div class="math">
<p><img src="../_images/math/a63a771117c8d7aa06d9a19ed0f8df2cdcf3fcf1.svg" alt="\underE{s_t, a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \Big| s_{t'}, a_{t'}, s_{t'+1}} = \int_{s_t, a_t} P(s_t, a_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}) \nabla_{\theta} \log \pi_{\theta}(a_t |s_t)."/></p>
</div><p>We now have to make a distinction between two cases: <img class="math" src="../_images/math/e5c189df93dba493361739f87479653a56ade5de.svg" alt="t' &lt; t"/>, the case where the reward happened before the action, and <img class="math" src="../_images/math/c4015c0090ba2d07e6258593ce4d66655ec88491.svg" alt="t' \geq t"/>, where it didn’t.</p>
<p><strong>Case One: Reward Before Action.</strong> If <img class="math" src="../_images/math/e5c189df93dba493361739f87479653a56ade5de.svg" alt="t' &lt; t"/>, then the conditional probabilities for actions at <img class="math" src="../_images/math/39079fcebc9eb2aba4ab3fe7359b34807ceccc0e.svg" alt="a_t"/> come from the policy:</p>
<div class="math">
<p><img src="../_images/math/af491f775e33314ba65c91aa7039502671302917.svg" alt="P(s_t, a_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}) &amp;= \pi_{\theta}(a_t | s_t) P(s_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}),"/></p>
</div><p>the innermost expectation can be broken down farther into</p>
<div class="math">
<p><img src="../_images/math/4ee031ed8d63ab8a05d64adb85171d7d23635e98.svg" alt="\underE{s_t, a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \Big| s_{t'}, a_{t'}, s_{t'+1}} &amp;= \int_{s_t, a_t} P(s_t, a_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}) \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \\
&amp;= \int_{s_t} P(s_t | \pi_{\theta}, s_{t'}, a_{t'}, s_{t'+1}) \int_{a_t} \pi_{\theta}(a_t | s_t) \nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \\
&amp;= \underE{s_t \sim \pi_{\theta}}{ \underE{a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \Big| s_t } \Big| s_{t'}, a_{t'}, s_{t'+1}}."/></p>
</div><p>The EGLP lemma says that</p>
<div class="math">
<p><img src="../_images/math/700dcf5d1f62a4b56e62d3d7dade322b3de765d6.svg" alt="\underE{a_t \sim \pi_{\theta}}{\nabla_{\theta} \log \pi_{\theta}(a_t |s_t) \Big| s_t } = 0,"/></p>
</div><p>allowing us to conclude that for <img class="math" src="../_images/math/e5c189df93dba493361739f87479653a56ade5de.svg" alt="t' &lt; t"/>, <img class="math" src="../_images/math/a3e53054646da1487c1a69c6542318aafc984ccd.svg" alt="\underE{\tau \sim \pi_{\theta}}{f(t,t')} = 0"/>.</p>
<p><strong>Case Two: Reward After Action.</strong> What about the <img class="math" src="../_images/math/c4015c0090ba2d07e6258593ce4d66655ec88491.svg" alt="t' \geq t"/> case, though? Why doesn’t the same logic apply? In this case, the conditional probabilities for <img class="math" src="../_images/math/39079fcebc9eb2aba4ab3fe7359b34807ceccc0e.svg" alt="a_t"/> can’t be broken down the same way, because you’re conditioning <strong>on the future.</strong> Think about it like this: let’s say that every day, in the morning, you make a choice between going for a jog and going to work early, and you have a 50-50 chance of each option. If you condition on a future where you went to work early, what are the odds that you went for a jog? Clearly, you didn’t. But if you’re conditioning on the past—before you made the decision—what are the odds that you will later go for a jog? Now it’s back to 50-50.</p>
<p>So in the case where <img class="math" src="../_images/math/c4015c0090ba2d07e6258593ce4d66655ec88491.svg" alt="t' \geq t"/>, the conditional distribution over actions <img class="math" src="../_images/math/39079fcebc9eb2aba4ab3fe7359b34807ceccc0e.svg" alt="a_t"/> is <strong>not</strong> <img class="math" src="../_images/math/a09b315bb707f75fa09522e99c2e28762d530e03.svg" alt="\pi(a_t|s_t)"/>, and the EGLP lemma does not apply.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Rick Staa

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>