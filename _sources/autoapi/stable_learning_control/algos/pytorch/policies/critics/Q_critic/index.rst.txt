stable_learning_control.algos.pytorch.policies.critics.Q_critic
===============================================================

.. py:module:: stable_learning_control.algos.pytorch.policies.critics.Q_critic

.. autoapi-nested-parse::

   Lyapunov actor critic policy.

   This module contains a Pytorch implementation of the Q Critic policy of
   `Haarnoja et al. 2019 <https://arxiv.org/abs/1812.05905>`_.



Classes
-------

.. autoapisummary::

   stable_learning_control.algos.pytorch.policies.critics.Q_critic.QCritic


Module Contents
---------------

.. py:class:: QCritic(obs_dim, act_dim, hidden_sizes, activation=nn.ReLU, output_activation=nn.Identity)

   Bases: :py:obj:`torch.nn.Module`


   Soft Q critic network.

   .. attribute:: Q

      The layers of the network.

      :type: torch.nn.Sequential

   Initialise the QCritic object.

   :param obs_dim: Dimension of the observation space.
   :type obs_dim: int
   :param act_dim: Dimension of the action space.
   :type act_dim: int
   :param hidden_sizes: Sizes of the hidden layers.
   :type hidden_sizes: list
   :param activation: The activation
                      function. Defaults to :obj:`torch.nn.ReLU`.
   :type activation: :obj:`torch.nn.modules.activation`, optional
   :param output_activation: The
                             activation function used for the output layers. Defaults to
                             :mod:`torch.nn.Identity`.
   :type output_activation: :obj:`torch.nn.modules.activation`, optional


   .. py:attribute:: __device_warning_logged
      :value: False



   .. py:attribute:: _obs_same_device
      :value: False



   .. py:attribute:: _act_same_device
      :value: False



   .. py:attribute:: Q


   .. py:method:: forward(obs, act)

      Perform forward pass through the network.

      :param obs: The tensor of observations.
      :type obs: torch.Tensor
      :param act: The tensor of actions.
      :type act: torch.Tensor

      :returns:     The tensor containing the Q values of the input observations and
                    actions.
      :rtype: torch.Tensor



