stable_learning_control.algos.pytorch.latc
==========================================

.. py:module:: stable_learning_control.algos.pytorch.latc

.. autoapi-nested-parse::

   A Lyapunov (soft) Actor-Twin Critic Agent.



Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/stable_learning_control/algos/pytorch/latc/latc/index


Functions
---------

.. autoapisummary::

   stable_learning_control.algos.pytorch.latc.latc


Package Contents
----------------

.. py:function:: latc(env_fn, actor_critic=None, *args, **kwargs)

   Trains the LATC algorithm in a given environment.

   :param env_fn: A function which creates a copy of the environment. The environment
                  must satisfy the gymnasium API.
   :param actor_critic: The constructor method for a
                        Torch Module with an ``act`` method, a ``pi`` module and several
                        ``Q`` or ``L`` modules. The ``act`` method and ``pi`` module should
                        accept batches of observations as inputs, and the ``Q*`` and ``L``
                        modules should accept a batch of observations and a batch of actions as
                        inputs. When called, these modules should return:

                        ===========  ================  ======================================
                        Call         Output Shape      Description
                        ===========  ================  ======================================
                        ``act``      (batch, act_dim)   | Numpy array of actions for each
                                                        | observation.
                        ``Q*/L``     (batch,)           | Tensor containing one current estimate
                                                        | of ``Q*/L`` for the provided
                                                        | observations and actions. (Critical:
                                                        | make sure to flatten this!)
                        ===========  ================  ======================================

                        Calling ``pi`` should return:

                        ===========  ================  ======================================
                        Symbol       Shape             Description
                        ===========  ================  ======================================
                        ``a``        (batch, act_dim)   | Tensor containing actions from policy
                                                        | given observations.
                        ``logp_pi``  (batch,)           | Tensor containing log probabilities of
                                                        | actions in ``a``. Importantly:
                                                        | gradients should be able to flow back
                                                        | into ``a``.
                        ===========  ================  ======================================

                        Defaults to
                        :class:`~stable_learning_control.algos.pytorch.policies.lyapunov_actor_twin_critic.LyapunovActorTwinCritic`
   :type actor_critic: torch.nn.Module, optional
   :param \*args: The positional arguments to pass to the :meth:`~stable_learning_control.algos.pytorch.lac.lac.lac` method.
   :param \*\*kwargs: The keyword arguments to pass to the :meth:`~stable_learning_control.algos.pytorch.lac.lac.lac` method.

   .. note::
       Wraps the :func:`~stable_learning_control.algos.pytorch.lac.lac.lac` function so
       that the :class:`~stable_learning_control.algos.pytorch.policies.lyapunov_actor_twin_critic.LyapunovActorTwinCritic`
       architecture is used as the actor critic.


