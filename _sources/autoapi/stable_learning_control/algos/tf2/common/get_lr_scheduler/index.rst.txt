stable_learning_control.algos.tf2.common.get_lr_scheduler
=========================================================

.. py:module:: stable_learning_control.algos.tf2.common.get_lr_scheduler

.. autoapi-nested-parse::

   Module used for creating TensorFlow learning rate schedulers.



Attributes
----------

.. autoapisummary::

   stable_learning_control.algos.tf2.common.get_lr_scheduler.tf


Functions
---------

.. autoapisummary::

   stable_learning_control.algos.tf2.common.get_lr_scheduler.get_lr_scheduler


Module Contents
---------------

.. py:data:: tf

.. py:function:: get_lr_scheduler(decaying_lr_type, lr_start, lr_final, steps)

   Creates a learning rate scheduler.

   :param decaying_lr_type: The learning rate decay type that is used (options are:
                            ``linear`` and ``exponential`` and ``constant``).
   :type decaying_lr_type: str
   :param lr_start: Initial learning rate.
   :type lr_start: float
   :param lr_final: Final learning rate.
   :type lr_final: float
   :param steps: Number of steps/epochs used in the training. This
                 includes the starting step/epoch.
   :type steps: int, optional

   :returns:

             A learning rate
                 scheduler object.
   :rtype: tensorflow.keras.optimizers.schedules.LearningRateSchedule

   .. seealso::
       See the :tf2:`TensorFlow <keras/optimizers/schedules>` documentation on how to
       implement other decay options.


